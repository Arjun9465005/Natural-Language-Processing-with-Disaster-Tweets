{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"},{"sourceId":9138306,"sourceType":"datasetVersion","datasetId":5518815}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dataset Used in This Project Will be Disaster Tweets Reviews","metadata":{}},{"cell_type":"code","source":"# Import Basis Libraries    \nimport pandas as pd\ndf_train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ndf_test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n# # rename column\n# df.rename(columns = {'label (depression result)':'Sentiment'}, inplace = True)\n# df.rename(columns = {'message to examine':'review'}, inplace = True)\n# # Drop Index Column\ndf_train","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:38.675789Z","iopub.execute_input":"2024-08-15T08:03:38.676205Z","iopub.status.idle":"2024-08-15T08:03:38.773903Z","shell.execute_reply.started":"2024-08-15T08:03:38.676153Z","shell.execute_reply":"2024-08-15T08:03:38.772740Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"         id keyword location  \\\n0         1     NaN      NaN   \n1         4     NaN      NaN   \n2         5     NaN      NaN   \n3         6     NaN      NaN   \n4         7     NaN      NaN   \n...     ...     ...      ...   \n7608  10869     NaN      NaN   \n7609  10870     NaN      NaN   \n7610  10871     NaN      NaN   \n7611  10872     NaN      NaN   \n7612  10873     NaN      NaN   \n\n                                                   text  target  \n0     Our Deeds are the Reason of this #earthquake M...       1  \n1                Forest fire near La Ronge Sask. Canada       1  \n2     All residents asked to 'shelter in place' are ...       1  \n3     13,000 people receive #wildfires evacuation or...       1  \n4     Just got sent this photo from Ruby #Alaska as ...       1  \n...                                                 ...     ...  \n7608  Two giant cranes holding a bridge collapse int...       1  \n7609  @aria_ahrary @TheTawniest The out of control w...       1  \n7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n7611  Police investigating after an e-bike collided ...       1  \n7612  The Latest: More Homes Razed by Northern Calif...       1  \n\n[7613 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>The Latest: More Homes Razed by Northern Calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Preprocessing ","metadata":{}},{"cell_type":"code","source":"# Check for null values in text columns\ntext_columns = ['keyword', 'location','text','target']  # Add the names of the text columns here\nnull_counts_text = df_train[text_columns].isnull().sum()\nprint(null_counts_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:39.941751Z","iopub.execute_input":"2024-08-15T08:03:39.942619Z","iopub.status.idle":"2024-08-15T08:03:39.959056Z","shell.execute_reply.started":"2024-08-15T08:03:39.942587Z","shell.execute_reply":"2024-08-15T08:03:39.957953Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"keyword       61\nlocation    2533\ntext           0\ntarget         0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train.shape\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:40.538674Z","iopub.execute_input":"2024-08-15T08:03:40.539053Z","iopub.status.idle":"2024-08-15T08:03:40.545542Z","shell.execute_reply.started":"2024-08-15T08:03:40.539021Z","shell.execute_reply":"2024-08-15T08:03:40.544606Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(7613, 5)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Removing the null columns in the dataset","metadata":{}},{"cell_type":"code","source":"df_train = df_train.drop(['location'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:41.351231Z","iopub.execute_input":"2024-08-15T08:03:41.352119Z","iopub.status.idle":"2024-08-15T08:03:41.358008Z","shell.execute_reply.started":"2024-08-15T08:03:41.352088Z","shell.execute_reply":"2024-08-15T08:03:41.356911Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:41.766726Z","iopub.execute_input":"2024-08-15T08:03:41.767706Z","iopub.status.idle":"2024-08-15T08:03:41.780288Z","shell.execute_reply.started":"2024-08-15T08:03:41.767671Z","shell.execute_reply":"2024-08-15T08:03:41.779228Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"         id keyword                                               text  target\n0         1     NaN  Our Deeds are the Reason of this #earthquake M...       1\n1         4     NaN             Forest fire near La Ronge Sask. Canada       1\n2         5     NaN  All residents asked to 'shelter in place' are ...       1\n3         6     NaN  13,000 people receive #wildfires evacuation or...       1\n4         7     NaN  Just got sent this photo from Ruby #Alaska as ...       1\n...     ...     ...                                                ...     ...\n7608  10869     NaN  Two giant cranes holding a bridge collapse int...       1\n7609  10870     NaN  @aria_ahrary @TheTawniest The out of control w...       1\n7610  10871     NaN  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n7611  10872     NaN  Police investigating after an e-bike collided ...       1\n7612  10873     NaN  The Latest: More Homes Razed by Northern Calif...       1\n\n[7613 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>Two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>Police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>The Latest: More Homes Razed by Northern Calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## LowerCasing Text","metadata":{}},{"cell_type":"code","source":"df_train['keyword'] = df_train['keyword'].str.lower()\ndf_train['text'] = df_train['text'].str.lower()\ndf_train","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:42.771366Z","iopub.execute_input":"2024-08-15T08:03:42.771791Z","iopub.status.idle":"2024-08-15T08:03:42.793367Z","shell.execute_reply.started":"2024-08-15T08:03:42.771759Z","shell.execute_reply":"2024-08-15T08:03:42.792356Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"         id keyword                                               text  target\n0         1     NaN  our deeds are the reason of this #earthquake m...       1\n1         4     NaN             forest fire near la ronge sask. canada       1\n2         5     NaN  all residents asked to 'shelter in place' are ...       1\n3         6     NaN  13,000 people receive #wildfires evacuation or...       1\n4         7     NaN  just got sent this photo from ruby #alaska as ...       1\n...     ...     ...                                                ...     ...\n7608  10869     NaN  two giant cranes holding a bridge collapse int...       1\n7609  10870     NaN  @aria_ahrary @thetawniest the out of control w...       1\n7610  10871     NaN  m1.94 [01:04 utc]?5km s of volcano hawaii. htt...       1\n7611  10872     NaN  police investigating after an e-bike collided ...       1\n7612  10873     NaN  the latest: more homes razed by northern calif...       1\n\n[7613 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>our deeds are the reason of this #earthquake m...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>forest fire near la ronge sask. canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>all residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>just got sent this photo from ruby #alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>@aria_ahrary @thetawniest the out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>m1.94 [01:04 utc]?5km s of volcano hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>the latest: more homes razed by northern calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Remove HTML Tags\n\n","metadata":{}},{"cell_type":"code","source":"# Import Regular Expression\nimport re\n\n# Function to remove HTML Tags\ndef remove_html_tags(text):\n    if isinstance(text, str):\n        pattern = re.compile('<.*?>')\n        return pattern.sub(r'', text)\n    return text  # Return the original value if it's not a string","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:43.736230Z","iopub.execute_input":"2024-08-15T08:03:43.736892Z","iopub.status.idle":"2024-08-15T08:03:43.741936Z","shell.execute_reply.started":"2024-08-15T08:03:43.736858Z","shell.execute_reply":"2024-08-15T08:03:43.740931Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Apply Function to Remove HTML Tags in our Dataset Colum Review.\ndf_train['keyword'] = df_train['keyword'].apply(remove_html_tags)\ndf_train['text'] = df_train['text'].apply(remove_html_tags)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:44.316302Z","iopub.execute_input":"2024-08-15T08:03:44.316915Z","iopub.status.idle":"2024-08-15T08:03:44.357604Z","shell.execute_reply.started":"2024-08-15T08:03:44.316884Z","shell.execute_reply":"2024-08-15T08:03:44.356752Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"         id keyword                                               text  target\n0         1     NaN  our deeds are the reason of this #earthquake m...       1\n1         4     NaN             forest fire near la ronge sask. canada       1\n2         5     NaN  all residents asked to 'shelter in place' are ...       1\n3         6     NaN  13,000 people receive #wildfires evacuation or...       1\n4         7     NaN  just got sent this photo from ruby #alaska as ...       1\n...     ...     ...                                                ...     ...\n7608  10869     NaN  two giant cranes holding a bridge collapse int...       1\n7609  10870     NaN  @aria_ahrary @thetawniest the out of control w...       1\n7610  10871     NaN  m1.94 [01:04 utc]?5km s of volcano hawaii. htt...       1\n7611  10872     NaN  police investigating after an e-bike collided ...       1\n7612  10873     NaN  the latest: more homes razed by northern calif...       1\n\n[7613 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>our deeds are the reason of this #earthquake m...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>forest fire near la ronge sask. canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>all residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>just got sent this photo from ruby #alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>@aria_ahrary @thetawniest the out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>m1.94 [01:04 utc]?5km s of volcano hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>the latest: more homes razed by northern calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Remove URLs","metadata":{}},{"cell_type":"code","source":"# Here We also Use Regular Expressions to Remove URLs from Text or Whole Corpus.\ndef remove_url(text):\n    if isinstance(text, str):\n        pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n        return pattern.sub(r'', text)\n    return text  # Return the original value if it's not a string","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:45.326539Z","iopub.execute_input":"2024-08-15T08:03:45.327256Z","iopub.status.idle":"2024-08-15T08:03:45.332003Z","shell.execute_reply.started":"2024-08-15T08:03:45.327221Z","shell.execute_reply":"2024-08-15T08:03:45.331035Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Apply Function to Remove URLs in our Dataset Colum Review.\ndf_train['keyword'] = df_train['keyword'].apply(remove_url)\ndf_train['text'] = df_train['text'].apply(remove_url)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:46.090792Z","iopub.execute_input":"2024-08-15T08:03:46.091198Z","iopub.status.idle":"2024-08-15T08:03:46.158419Z","shell.execute_reply.started":"2024-08-15T08:03:46.091146Z","shell.execute_reply":"2024-08-15T08:03:46.157402Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"         id keyword                                               text  target\n0         1     NaN  our deeds are the reason of this #earthquake m...       1\n1         4     NaN             forest fire near la ronge sask. canada       1\n2         5     NaN  all residents asked to 'shelter in place' are ...       1\n3         6     NaN  13,000 people receive #wildfires evacuation or...       1\n4         7     NaN  just got sent this photo from ruby #alaska as ...       1\n...     ...     ...                                                ...     ...\n7608  10869     NaN  two giant cranes holding a bridge collapse int...       1\n7609  10870     NaN  @aria_ahrary @thetawniest the out of control w...       1\n7610  10871     NaN        m1.94 [01:04 utc]?5km s of volcano hawaii.        1\n7611  10872     NaN  police investigating after an e-bike collided ...       1\n7612  10873     NaN  the latest: more homes razed by northern calif...       1\n\n[7613 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>our deeds are the reason of this #earthquake m...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>forest fire near la ronge sask. canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>all residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>just got sent this photo from ruby #alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>@aria_ahrary @thetawniest the out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>m1.94 [01:04 utc]?5km s of volcano hawaii.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>the latest: more homes razed by northern calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Remove Punctuations\n\n","metadata":{}},{"cell_type":"code","source":"# From String we Imorts Punctuation.\nimport string\nstring.punctuation","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:47.266471Z","iopub.execute_input":"2024-08-15T08:03:47.266876Z","iopub.status.idle":"2024-08-15T08:03:47.273097Z","shell.execute_reply.started":"2024-08-15T08:03:47.266845Z","shell.execute_reply":"2024-08-15T08:03:47.272106Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"},"metadata":{}}]},{"cell_type":"code","source":"# Storing Punctuation in a Variable\npunc = string.punctuation","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:48.451576Z","iopub.execute_input":"2024-08-15T08:03:48.451982Z","iopub.status.idle":"2024-08-15T08:03:48.456546Z","shell.execute_reply.started":"2024-08-15T08:03:48.451931Z","shell.execute_reply":"2024-08-15T08:03:48.455484Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# The code defines a function, remove_punc1, that takes a text input and removes all punctuation characters from it using\n# the translate method with a translation table created by str.maketrans. This function effectively cleanses the text of punctuation symbols.\ndef remove_punc(text):\n    if isinstance(text, str):\n        return text.translate(str.maketrans('', '', string.punctuation))\n    return text  # Return the original value if it's not a string","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:49.038178Z","iopub.execute_input":"2024-08-15T08:03:49.038536Z","iopub.status.idle":"2024-08-15T08:03:49.043792Z","shell.execute_reply.started":"2024-08-15T08:03:49.038507Z","shell.execute_reply":"2024-08-15T08:03:49.042657Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Apply Function to Remove punctuations in our Dataset Colum Review.\ndf_train['keyword'] = df_train['keyword'].apply(remove_punc)\ndf_train['text'] = df_train['text'].apply(remove_punc)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:49.536412Z","iopub.execute_input":"2024-08-15T08:03:49.536841Z","iopub.status.idle":"2024-08-15T08:03:49.625029Z","shell.execute_reply.started":"2024-08-15T08:03:49.536812Z","shell.execute_reply":"2024-08-15T08:03:49.623966Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"         id keyword                                               text  target\n0         1     NaN  our deeds are the reason of this earthquake ma...       1\n1         4     NaN              forest fire near la ronge sask canada       1\n2         5     NaN  all residents asked to shelter in place are be...       1\n3         6     NaN  13000 people receive wildfires evacuation orde...       1\n4         7     NaN  just got sent this photo from ruby alaska as s...       1\n...     ...     ...                                                ...     ...\n7608  10869     NaN  two giant cranes holding a bridge collapse int...       1\n7609  10870     NaN  ariaahrary thetawniest the out of control wild...       1\n7610  10871     NaN              m194 0104 utc5km s of volcano hawaii        1\n7611  10872     NaN  police investigating after an ebike collided w...       1\n7612  10873     NaN  the latest more homes razed by northern califo...       1\n\n[7613 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>our deeds are the reason of this earthquake ma...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>forest fire near la ronge sask canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>all residents asked to shelter in place are be...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>13000 people receive wildfires evacuation orde...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>just got sent this photo from ruby alaska as s...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>ariaahrary thetawniest the out of control wild...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>m194 0104 utc5km s of volcano hawaii</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>police investigating after an ebike collided w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>the latest more homes razed by northern califo...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Handling ChatWords\n\n","metadata":{}},{"cell_type":"code","source":"# Here Come ChatWords Which i Get from a Github Repository\n# Repository Link : https://github.com/rishabhverma17/sms_slang_translator/blob/master/slang.txt\nchat_words = {\n    \"AFAIK\": \"As Far As I Know\",\n    \"AFK\": \"Away From Keyboard\",\n    \"ASAP\": \"As Soon As Possible\",\n    \"ATK\": \"At The Keyboard\",\n    \"ATM\": \"At The Moment\",\n    \"A3\": \"Anytime, Anywhere, Anyplace\",\n    \"BAK\": \"Back At Keyboard\",\n    \"BBL\": \"Be Back Later\",\n    \"BBS\": \"Be Back Soon\",\n    \"BFN\": \"Bye For Now\",\n    \"B4N\": \"Bye For Now\",\n    \"BRB\": \"Be Right Back\",\n    \"BRT\": \"Be Right There\",\n    \"BTW\": \"By The Way\",\n    \"B4\": \"Before\",\n    \"B4N\": \"Bye For Now\",\n    \"CU\": \"See You\",\n    \"CUL8R\": \"See You Later\",\n    \"CYA\": \"See You\",\n    \"FAQ\": \"Frequently Asked Questions\",\n    \"FC\": \"Fingers Crossed\",\n    \"FWIW\": \"For What It's Worth\",\n    \"FYI\": \"For Your Information\",\n    \"GAL\": \"Get A Life\",\n    \"GG\": \"Good Game\",\n    \"GN\": \"Good Night\",\n    \"GMTA\": \"Great Minds Think Alike\",\n    \"GR8\": \"Great!\",\n    \"G9\": \"Genius\",\n    \"IC\": \"I See\",\n    \"ICQ\": \"I Seek you (also a chat program)\",\n    \"ILU\": \"ILU: I Love You\",\n    \"IMHO\": \"In My Honest/Humble Opinion\",\n    \"IMO\": \"In My Opinion\",\n    \"IOW\": \"In Other Words\",\n    \"IRL\": \"In Real Life\",\n    \"KISS\": \"Keep It Simple, Stupid\",\n    \"LDR\": \"Long Distance Relationship\",\n    \"LMAO\": \"Laugh My A.. Off\",\n    \"LOL\": \"Laughing Out Loud\",\n    \"LTNS\": \"Long Time No See\",\n    \"L8R\": \"Later\",\n    \"MTE\": \"My Thoughts Exactly\",\n    \"M8\": \"Mate\",\n    \"NRN\": \"No Reply Necessary\",\n    \"OIC\": \"Oh I See\",\n    \"PITA\": \"Pain In The A..\",\n    \"PRT\": \"Party\",\n    \"PRW\": \"Parents Are Watching\",\n    \"QPSA?\": \"Que Pasa?\",\n    \"ROFL\": \"Rolling On The Floor Laughing\",\n    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n    \"SK8\": \"Skate\",\n    \"STATS\": \"Your sex and age\",\n    \"ASL\": \"Age, Sex, Location\",\n    \"THX\": \"Thank You\",\n    \"TTFN\": \"Ta-Ta For Now!\",\n    \"TTYL\": \"Talk To You Later\",\n    \"U\": \"You\",\n    \"U2\": \"You Too\",\n    \"U4E\": \"Yours For Ever\",\n    \"WB\": \"Welcome Back\",\n    \"WTF\": \"What The F...\",\n    \"WTG\": \"Way To Go!\",\n    \"WUF\": \"Where Are You From?\",\n    \"W8\": \"Wait...\",\n    \"7K\": \"Sick:-D Laugher\",\n    \"TFW\": \"That feeling when\",\n    \"MFW\": \"My face when\",\n    \"MRW\": \"My reaction when\",\n    \"IFYP\": \"I feel your pain\",\n    \"TNTL\": \"Trying not to laugh\",\n    \"JK\": \"Just kidding\",\n    \"IDC\": \"I don't care\",\n    \"ILY\": \"I love you\",\n    \"IMU\": \"I miss you\",\n    \"ADIH\": \"Another day in hell\",\n    \"ZZZ\": \"Sleeping, bored, tired\",\n    \"WYWH\": \"Wish you were here\",\n    \"TIME\": \"Tears in my eyes\",\n    \"BAE\": \"Before anyone else\",\n    \"FIMH\": \"Forever in my heart\",\n    \"BSAAW\": \"Big smile and a wink\",\n    \"BWL\": \"Bursting with laughter\",\n    \"BFF\": \"Best friends forever\",\n    \"CSL\": \"Can't stop laughing\"\n}","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:50.802534Z","iopub.execute_input":"2024-08-15T08:03:50.802919Z","iopub.status.idle":"2024-08-15T08:03:50.816452Z","shell.execute_reply.started":"2024-08-15T08:03:50.802889Z","shell.execute_reply":"2024-08-15T08:03:50.815326Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Function\ndef chat_conversion(text):\n    if isinstance(text, str):\n        new_text = []\n        for i in text.split():\n            if i.upper() in chat_words:\n                new_text.append(chat_words[i.upper()])\n            else:\n                new_text.append(i)\n        return \" \".join(new_text)\n    return text  # Return the original value if it's not a string","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:51.310983Z","iopub.execute_input":"2024-08-15T08:03:51.311645Z","iopub.status.idle":"2024-08-15T08:03:51.317524Z","shell.execute_reply.started":"2024-08-15T08:03:51.311611Z","shell.execute_reply":"2024-08-15T08:03:51.316483Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Apply Function to Handling ChatWordss in our Dataset Colum Review.\ndf_train['keyword'] = df_train['keyword'].apply(chat_conversion)\ndf_train['text'] = df_train['text'].apply(chat_conversion)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:52.141229Z","iopub.execute_input":"2024-08-15T08:03:52.141629Z","iopub.status.idle":"2024-08-15T08:03:52.216664Z","shell.execute_reply.started":"2024-08-15T08:03:52.141596Z","shell.execute_reply":"2024-08-15T08:03:52.215652Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"         id keyword                                               text  target\n0         1     NaN  our deeds are the reason of this earthquake ma...       1\n1         4     NaN              forest fire near la ronge sask canada       1\n2         5     NaN  all residents asked to shelter in place are be...       1\n3         6     NaN  13000 people receive wildfires evacuation orde...       1\n4         7     NaN  just got sent this photo from ruby alaska as s...       1\n...     ...     ...                                                ...     ...\n7608  10869     NaN  two giant cranes holding a bridge collapse int...       1\n7609  10870     NaN  ariaahrary thetawniest the out of control wild...       1\n7610  10871     NaN               m194 0104 utc5km s of volcano hawaii       1\n7611  10872     NaN  police investigating after an ebike collided w...       1\n7612  10873     NaN  the latest more homes razed by northern califo...       1\n\n[7613 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>our deeds are the reason of this earthquake ma...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>forest fire near la ronge sask canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>all residents asked to shelter in place are be...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>13000 people receive wildfires evacuation orde...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>just got sent this photo from ruby alaska as s...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>ariaahrary thetawniest the out of control wild...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>m194 0104 utc5km s of volcano hawaii</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>police investigating after an ebike collided w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>the latest more homes razed by northern califo...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Spelling Correction\n\n","metadata":{}},{"cell_type":"code","source":"pip install symspellpy","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:03:56.201455Z","iopub.execute_input":"2024-08-15T08:03:56.202378Z","iopub.status.idle":"2024-08-15T08:04:31.176213Z","shell.execute_reply.started":"2024-08-15T08:03:56.202344Z","shell.execute_reply":"2024-08-15T08:04:31.174913Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting symspellpy\n  Downloading symspellpy-6.7.7-py3-none-any.whl.metadata (2.5 kB)\nCollecting editdistpy>=0.1.3 (from symspellpy)\n  Downloading editdistpy-0.1.4.tar.gz (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hDownloading symspellpy-6.7.7-py3-none-any.whl (2.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: editdistpy\n  Building wheel for editdistpy (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for editdistpy: filename=editdistpy-0.1.4-cp310-cp310-linux_x86_64.whl size=50354 sha256=ad9c29e1d8204e435fa7596b5ceb9cd0d1d01f5e2f3732cda6698fd1f9be172d\n  Stored in directory: /root/.cache/pip/wheels/4c/0f/10/c20d67cd765ee5b3666d759a307241bba0663135d6ee1c0072\nSuccessfully built editdistpy\nInstalling collected packages: editdistpy, symspellpy\nSuccessfully installed editdistpy-0.1.4 symspellpy-6.7.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom symspellpy import SymSpell, Verbosity\n\n# Initialize SymSpell object\nsym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n\n# Load the frequency dictionary\ndictionary_path = \"/kaggle/input/dictionary-spell-check/frequency_dictionary_en_82_765.txt\"  # Path to the exact file\nsym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n\n# Define the spelling correction function using SymSpell\ndef correct_spelling_symspell(text):\n    # Check if the input is a string\n    if isinstance(text, str):\n        # Get the corrected spelling suggestions\n        suggestions = sym_spell.lookup_compound(text, max_edit_distance=2)\n        # Return the first suggestion (best correction) or the original text if no suggestions\n        return suggestions[0].term if suggestions else text\n    else:\n        # If it's not a string, return it as is (or handle NaN cases)\n        return text\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:04:34.471644Z","iopub.execute_input":"2024-08-15T08:04:34.472650Z","iopub.status.idle":"2024-08-15T08:04:38.698566Z","shell.execute_reply.started":"2024-08-15T08:04:34.472616Z","shell.execute_reply":"2024-08-15T08:04:38.697573Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Apply the spelling correction function to the 'text_column'\ndf_train['keyword'] = df_train['keyword'].apply(correct_spelling_symspell)\ndf_train['text'] = df_train['text'].apply(correct_spelling_symspell)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:04:38.700453Z","iopub.execute_input":"2024-08-15T08:04:38.700778Z","iopub.status.idle":"2024-08-15T08:05:36.266666Z","shell.execute_reply.started":"2024-08-15T08:04:38.700749Z","shell.execute_reply":"2024-08-15T08:05:36.265500Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:05:36.268097Z","iopub.execute_input":"2024-08-15T08:05:36.268464Z","iopub.status.idle":"2024-08-15T08:05:36.282229Z","shell.execute_reply.started":"2024-08-15T08:05:36.268434Z","shell.execute_reply":"2024-08-15T08:05:36.280967Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"         id keyword                                               text  target\n0         1     NaN  our deeds are ﻿the reason of this earthquake m...       1\n1         4     NaN              forest fire near la range sask canada       1\n2         5     NaN  all residents asked to shelter in place are be...       1\n3         6     NaN  13000 people receive wildfires evacuation orde...       1\n4         7     NaN  just got sent this photo from ruby alaska as s...       1\n...     ...     ...                                                ...     ...\n7608  10869     NaN  two giant cranes holding a bridge collapse int...       1\n7609  10870     NaN  aria harry theta nest ﻿the out of control wild...       1\n7610  10871     NaN             my of of of it com a of volcano hawaii       1\n7611  10872     NaN  police investigating after an bike collided wi...       1\n7612  10873     NaN  ﻿the latest more homes razed by northern calif...       1\n\n[7613 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>our deeds are ﻿the reason of this earthquake m...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>forest fire near la range sask canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>all residents asked to shelter in place are be...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>13000 people receive wildfires evacuation orde...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>just got sent this photo from ruby alaska as s...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>aria harry theta nest ﻿the out of control wild...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>my of of of it com a of volcano hawaii</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>police investigating after an bike collided wi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>﻿the latest more homes razed by northern calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Handling StopWords\n\n","metadata":{}},{"cell_type":"code","source":"# We use NLTK library to remove Stopwords.\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:05:58.481220Z","iopub.execute_input":"2024-08-15T08:05:58.481640Z","iopub.status.idle":"2024-08-15T08:06:00.196554Z","shell.execute_reply.started":"2024-08-15T08:05:58.481609Z","shell.execute_reply":"2024-08-15T08:06:00.195647Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Here we can see all the stopwords in English.However we can chose different Languages also like spanish etc.\nstopword = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:06:00.198364Z","iopub.execute_input":"2024-08-15T08:06:00.198697Z","iopub.status.idle":"2024-08-15T08:06:00.207756Z","shell.execute_reply.started":"2024-08-15T08:06:00.198668Z","shell.execute_reply":"2024-08-15T08:06:00.206847Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Function\ndef remove_stopwords(text):\n    # Check if the input is a string\n    if isinstance(text, str):\n        new_text = []\n        for word in text.split():\n            # Append non-stopwords to new_text\n            if word.lower() not in stopword:\n                new_text.append(word)\n        # Return the processed text\n        return ' '.join(new_text)\n    else:\n        # If the input is not a string, return it as is\n        return text","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:06:00.208894Z","iopub.execute_input":"2024-08-15T08:06:00.209186Z","iopub.status.idle":"2024-08-15T08:06:00.217428Z","shell.execute_reply.started":"2024-08-15T08:06:00.209141Z","shell.execute_reply":"2024-08-15T08:06:00.216540Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# We can Apply the same Function on Whole Corpus also \ndf_train['keyword'] = df_train['keyword'].apply(remove_stopwords)\ndf_train['text'] = df_train['text'].apply(remove_stopwords)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:06:01.904916Z","iopub.execute_input":"2024-08-15T08:06:01.905365Z","iopub.status.idle":"2024-08-15T08:06:02.209538Z","shell.execute_reply.started":"2024-08-15T08:06:01.905335Z","shell.execute_reply":"2024-08-15T08:06:02.208421Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"         id keyword                                               text  target\n0         1     NaN  deeds ﻿the reason earthquake may allah forgive us       1\n1         4     NaN              forest fire near la range sask canada       1\n2         5     NaN  residents asked shelter place notified officer...       1\n3         6     NaN  13000 people receive wildfires evacuation orde...       1\n4         7     NaN  got sent photo ruby alaska smoke wildfires pou...       1\n...     ...     ...                                                ...     ...\n7608  10869     NaN  two giant cranes holding bridge collapse nearb...       1\n7609  10870     NaN  aria harry theta nest ﻿the control wild fires ...       1\n7610  10871     NaN                                 com volcano hawaii       1\n7611  10872     NaN  police investigating bike collided car little ...       1\n7612  10873     NaN  ﻿the latest homes razed northern california wi...       1\n\n[7613 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>deeds ﻿the reason earthquake may allah forgive us</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>forest fire near la range sask canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>residents asked shelter place notified officer...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>13000 people receive wildfires evacuation orde...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>two giant cranes holding bridge collapse nearb...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>aria harry theta nest ﻿the control wild fires ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>com volcano hawaii</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>police investigating bike collided car little ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>﻿the latest homes razed northern california wi...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Handling Emojies\n\n","metadata":{}},{"cell_type":"code","source":"# Again Here we use The Regular Expressions to Remove the Emojies from Text or Whole Corpus.\ndef remove_emoji(text):\n    # Define the emoji pattern\n    emoji_pattern = re.compile(\n        \"[\"  # Start of the character set\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n        u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n        u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n        u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n        u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n        u\"\\U00002702-\\U000027B0\"  # Dingbats\n        u\"\\U000024C2-\\U0001F251\"  # Enclosed Characters\n        \"]+\", flags=re.UNICODE\n    )\n    # Check if text is a string\n    if isinstance(text, str):\n        return emoji_pattern.sub(r'', text)\n    else:\n        return text","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:06:03.576102Z","iopub.execute_input":"2024-08-15T08:06:03.577071Z","iopub.status.idle":"2024-08-15T08:06:03.583086Z","shell.execute_reply.started":"2024-08-15T08:06:03.577024Z","shell.execute_reply":"2024-08-15T08:06:03.582132Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"df_train['keyword'] = df_train['keyword'].apply(remove_emoji)\ndf_train['text'] =  df_train['text'].apply(remove_emoji)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:06:04.210646Z","iopub.execute_input":"2024-08-15T08:06:04.211374Z","iopub.status.idle":"2024-08-15T08:06:04.297826Z","shell.execute_reply.started":"2024-08-15T08:06:04.211338Z","shell.execute_reply":"2024-08-15T08:06:04.297021Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:06:04.920924Z","iopub.execute_input":"2024-08-15T08:06:04.921333Z","iopub.status.idle":"2024-08-15T08:06:04.934017Z","shell.execute_reply.started":"2024-08-15T08:06:04.921300Z","shell.execute_reply":"2024-08-15T08:06:04.933021Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"         id keyword                                               text  target\n0         1     NaN   deeds the reason earthquake may allah forgive us       1\n1         4     NaN              forest fire near la range sask canada       1\n2         5     NaN  residents asked shelter place notified officer...       1\n3         6     NaN  13000 people receive wildfires evacuation orde...       1\n4         7     NaN  got sent photo ruby alaska smoke wildfires pou...       1\n...     ...     ...                                                ...     ...\n7608  10869     NaN  two giant cranes holding bridge collapse nearb...       1\n7609  10870     NaN  aria harry theta nest the control wild fires c...       1\n7610  10871     NaN                                 com volcano hawaii       1\n7611  10872     NaN  police investigating bike collided car little ...       1\n7612  10873     NaN  the latest homes razed northern california wil...       1\n\n[7613 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>deeds the reason earthquake may allah forgive us</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>forest fire near la range sask canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>residents asked shelter place notified officer...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>13000 people receive wildfires evacuation orde...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>two giant cranes holding bridge collapse nearb...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>aria harry theta nest the control wild fires c...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>com volcano hawaii</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>police investigating bike collided car little ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>the latest homes razed northern california wil...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Assuming your target column is named 'Response'\ntarget_counts = df_train['target'].value_counts()\n\n# Display the counts\nprint(target_counts)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:06:06.044208Z","iopub.execute_input":"2024-08-15T08:06:06.044655Z","iopub.status.idle":"2024-08-15T08:06:06.056638Z","shell.execute_reply.started":"2024-08-15T08:06:06.044622Z","shell.execute_reply":"2024-08-15T08:06:06.055551Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"target\n0    4342\n1    3271\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport gensim\nfrom gensim.utils import simple_preprocess\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n\n# Step 2: Tokenize the 'keyword' and 'text' Columns\ndf_train['tokenized_keyword'] = df_train['keyword'].apply(lambda x: simple_preprocess(str(x)))\ndf_train['tokenized_text'] = df_train['text'].apply(lambda x: simple_preprocess(str(x)))\n\n# Step 3: Combine the Tokenized Columns\ndf_train['combined_text'] = df_train['tokenized_keyword'].apply(' '.join) + ' ' + df_train['tokenized_text'].apply(' '.join)\n\n# Step 4: Vectorize the Combined Text Data Using TF-IDF\ntfidf_vectorizer = TfidfVectorizer()\nX = tfidf_vectorizer.fit_transform(df_train['combined_text'])\n\n# The target variable\ny = df_train['target']\n\n# Step 5: Split the Data into Training and Testing Sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 6: Train the RandomForest Model\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Step 7: Make Predictions and Evaluate the Model\ny_pred = rf_model.predict(X_test)\n\n# Calculate the accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.4f}\")\n\n# Generate the confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:22:56.774117Z","iopub.execute_input":"2024-08-14T17:22:56.774540Z","iopub.status.idle":"2024-08-14T17:23:28.682858Z","shell.execute_reply.started":"2024-08-14T17:22:56.774502Z","shell.execute_reply":"2024-08-14T17:23:28.681841Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"Accuracy: 0.7820\nConfusion Matrix:\n[[754 120]\n [212 437]]\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train['combined_text']","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:26:06.154352Z","iopub.execute_input":"2024-08-14T17:26:06.155117Z","iopub.status.idle":"2024-08-14T17:26:06.163398Z","shell.execute_reply.started":"2024-08-14T17:26:06.155084Z","shell.execute_reply":"2024-08-14T17:26:06.162313Z"},"trusted":true},"execution_count":116,"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"0       nan deeds the reason earthquake may allah forg...\n1               nan forest fire near la range sask canada\n2       nan residents asked shelter place notified off...\n3       nan people receive wildfires evacuation orders...\n4       nan got sent photo ruby alaska smoke wildfires...\n                              ...                        \n7608    nan two giant cranes holding bridge collapse n...\n7609    nan aria harry theta nest the control wild fir...\n7610                               nan com volcano hawaii\n7611    nan police investigating bike collided car lit...\n7612    nan the latest homes razed northern california...\nName: combined_text, Length: 7613, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Features and target variable\nX = df_train.drop('target', axis=1)  \ny = df_train['target']  \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:16:32.984614Z","iopub.execute_input":"2024-08-14T16:16:32.985201Z","iopub.status.idle":"2024-08-14T16:16:32.999899Z","shell.execute_reply.started":"2024-08-14T16:16:32.985150Z","shell.execute_reply":"2024-08-14T16:16:32.998666Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:16:34.825283Z","iopub.execute_input":"2024-08-14T16:16:34.826049Z","iopub.status.idle":"2024-08-14T16:16:34.833434Z","shell.execute_reply.started":"2024-08-14T16:16:34.826010Z","shell.execute_reply":"2024-08-14T16:16:34.832280Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"(5329, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"## using Bags of Words","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\n\nX_train_bow = cv.fit_transform(X_train['text']).toarray()\nX_test_bow =  cv.transform(X_test['text']).toarray()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:58:57.355777Z","iopub.execute_input":"2024-08-14T16:58:57.356664Z","iopub.status.idle":"2024-08-14T16:58:57.664694Z","shell.execute_reply.started":"2024-08-14T16:58:57.356627Z","shell.execute_reply":"2024-08-14T16:58:57.663862Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"X_train_bow.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:26:57.100139Z","iopub.execute_input":"2024-08-14T16:26:57.100932Z","iopub.status.idle":"2024-08-14T16:26:57.108020Z","shell.execute_reply.started":"2024-08-14T16:26:57.100892Z","shell.execute_reply":"2024-08-14T16:26:57.106808Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"(5329, 10751)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Naive Bays algo","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\n\ngnb.fit(X_train_bow, y_train)\n\ny_pred = gnb.predict(X_test_bow)\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix\naccuracy_score(y_test,y_pred)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:16:56.449780Z","iopub.execute_input":"2024-08-14T16:16:56.450190Z","iopub.status.idle":"2024-08-14T16:16:56.901745Z","shell.execute_reply.started":"2024-08-14T16:16:56.450157Z","shell.execute_reply":"2024-08-14T16:16:56.900498Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"0.6120840630472855"},"metadata":{}}]},{"cell_type":"markdown","source":"# Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Initialize the RandomForestClassifier\nrf_clf = RandomForestClassifier(random_state=42)\n\n# Fit the model on the training data\nrf_clf.fit(X_train_bow, y_train)\n\n# Predict on the test data\ny_pred_rf = rf_clf.predict(X_test_bow)\n\n# Calculate accuracy\naccuracy_rf = accuracy_score(y_test, y_pred_rf)\n\n# Print the accuracy\nprint(\"Random Forest Classifier Accuracy:\", accuracy_rf)\n\n# Optionally, print the confusion matrix\nconf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\nprint(\"Confusion Matrix:\\n\", conf_matrix_rf)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:20:44.463726Z","iopub.execute_input":"2024-08-14T16:20:44.464734Z","iopub.status.idle":"2024-08-14T16:21:58.370975Z","shell.execute_reply.started":"2024-08-14T16:20:44.464692Z","shell.execute_reply":"2024-08-14T16:21:58.369807Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"Random Forest Classifier Accuracy: 0.7898423817863398\nConfusion Matrix:\n [[1154  164]\n [ 316  650]]\n","output_type":"stream"}]},{"cell_type":"code","source":"cv = CountVectorizer(ngram_range=(1,3))\n\nX_train_bow = cv.fit_transform(X_train['text']).toarray()\nX_test_bow =  cv.transform(X_test['text']).toarray()\n\n\n# Initialize the RandomForestClassifier\nrf_clf = RandomForestClassifier(random_state=42)\n\n# Fit the model on the training data\nrf_clf.fit(X_train_bow, y_train)\n\n# Predict on the test data\ny_pred_rf = rf_clf.predict(X_test_bow)\n\n# Calculate accuracy\naccuracy_rf = accuracy_score(y_test, y_pred_rf)\n\n# Print the accuracy\nprint(\"Random Forest Classifier Accuracy:\", accuracy_rf)\n\n# Optionally, print the confusion matrix\nconf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\nprint(\"Confusion Matrix:\\n\", conf_matrix_rf)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:32:39.522166Z","iopub.execute_input":"2024-08-14T16:32:39.522588Z","iopub.status.idle":"2024-08-14T16:37:53.474497Z","shell.execute_reply.started":"2024-08-14T16:32:39.522556Z","shell.execute_reply":"2024-08-14T16:37:53.473453Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"Random Forest Classifier Accuracy: 0.7837127845884413\nConfusion Matrix:\n [[1226   92]\n [ 402  564]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Using TF-IDF","metadata":{}},{"cell_type":"code","source":"df_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:46:38.730049Z","iopub.execute_input":"2024-08-14T16:46:38.730891Z","iopub.status.idle":"2024-08-14T16:46:38.737507Z","shell.execute_reply.started":"2024-08-14T16:46:38.730855Z","shell.execute_reply":"2024-08-14T16:46:38.736487Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"(7613, 4)"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n\n# Features and target variable\nX = df_train.drop('target', axis=1)  \ny = df_train['target']  \n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Initialize the TF-IDF Vectorizer\ntfidf = TfidfVectorizer()\n\n# Fit and transform the training data, and transform the testing data\nX_train_tfidf = tfidf.fit_transform(X_train['text']).toarray()\nX_test_tfidf = tfidf.transform(X_test['text']).toarray()\n\n\nX_train_tfidf.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:47:45.859746Z","iopub.execute_input":"2024-08-14T16:47:45.860622Z","iopub.status.idle":"2024-08-14T16:47:46.338006Z","shell.execute_reply.started":"2024-08-14T16:47:45.860581Z","shell.execute_reply":"2024-08-14T16:47:46.336870Z"},"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"(5329, 10751)"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize the Gaussian Naive Bayes model\ngnb = GaussianNB()\n\n# Train the model\ngnb.fit(X_train_tfidf, y_train)\n\n# Make predictions on the test data\ny_pred = gnb.predict(X_test_tfidf)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Confusion Matrix:\\n{conf_matrix}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:49:09.444616Z","iopub.execute_input":"2024-08-14T16:49:09.445338Z","iopub.status.idle":"2024-08-14T16:49:10.719871Z","shell.execute_reply.started":"2024-08-14T16:49:09.445300Z","shell.execute_reply":"2024-08-14T16:49:10.718859Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"Accuracy: 0.6063922942206655\nConfusion Matrix:\n[[665 653]\n [246 720]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## word2vec","metadata":{}},{"cell_type":"code","source":"import gensim\nfrom nltk import sent_tokenize\nfrom gensim.utils import simple_preprocess","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:36:34.801844Z","iopub.execute_input":"2024-08-14T17:36:34.802533Z","iopub.status.idle":"2024-08-14T17:36:34.807057Z","shell.execute_reply.started":"2024-08-14T17:36:34.802496Z","shell.execute_reply":"2024-08-14T17:36:34.806038Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"story = []\nfor doc in df_train['text']:\n    raw_sent = sent_tokenize(doc)\n    for sent in raw_sent:\n        story.append(simple_preprocess(sent))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:36:35.389977Z","iopub.execute_input":"2024-08-14T17:36:35.390692Z","iopub.status.idle":"2024-08-14T17:36:35.921490Z","shell.execute_reply.started":"2024-08-14T17:36:35.390657Z","shell.execute_reply":"2024-08-14T17:36:35.920688Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"model =  gensim.models.Word2Vec(\n    window = 10,\n    min_count =2\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:38:48.735023Z","iopub.execute_input":"2024-08-14T17:38:48.735661Z","iopub.status.idle":"2024-08-14T17:38:48.740721Z","shell.execute_reply.started":"2024-08-14T17:38:48.735627Z","shell.execute_reply":"2024-08-14T17:38:48.739817Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"model.build_vocab(story)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:39:06.229616Z","iopub.execute_input":"2024-08-14T17:39:06.230404Z","iopub.status.idle":"2024-08-14T17:39:06.465763Z","shell.execute_reply.started":"2024-08-14T17:39:06.230371Z","shell.execute_reply":"2024-08-14T17:39:06.464847Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"model.train(story, total_examples=model.corpus_count, epochs=model.epochs)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:40:29.405551Z","iopub.execute_input":"2024-08-14T17:40:29.405907Z","iopub.status.idle":"2024-08-14T17:40:29.854642Z","shell.execute_reply.started":"2024-08-14T17:40:29.405880Z","shell.execute_reply":"2024-08-14T17:40:29.853559Z"},"trusted":true},"execution_count":131,"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"(321777, 370010)"},"metadata":{}}]},{"cell_type":"code","source":"total_examples=model.corpus_count\nprint(total_examples)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T18:10:33.881343Z","iopub.execute_input":"2024-08-14T18:10:33.882370Z","iopub.status.idle":"2024-08-14T18:10:33.887373Z","shell.execute_reply.started":"2024-08-14T18:10:33.882326Z","shell.execute_reply":"2024-08-14T18:10:33.886452Z"},"trusted":true},"execution_count":150,"outputs":[{"name":"stdout","text":"7613\n","output_type":"stream"}]},{"cell_type":"code","source":"len(model.wv.index_to_key)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:41:28.353600Z","iopub.execute_input":"2024-08-14T17:41:28.354285Z","iopub.status.idle":"2024-08-14T17:41:28.360682Z","shell.execute_reply.started":"2024-08-14T17:41:28.354250Z","shell.execute_reply":"2024-08-14T17:41:28.359701Z"},"trusted":true},"execution_count":132,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"6485"},"metadata":{}}]},{"cell_type":"code","source":"def document_vector(doc):\n    doc = [word for word in doc.split() if word in model.wv.index_to_key]\n      # Check if the document has valid words\n    if len(doc) == 0:\n        # Return a zero vector if no words are in the vocabulary\n        return np.zeros(model.vector_size)\n    return np.mean(model.wv[doc],axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:55:09.625319Z","iopub.execute_input":"2024-08-14T17:55:09.625833Z","iopub.status.idle":"2024-08-14T17:55:09.632339Z","shell.execute_reply.started":"2024-08-14T17:55:09.625798Z","shell.execute_reply":"2024-08-14T17:55:09.631042Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"import numpy as np \ndocument_vector(df_train['text'].values[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:55:10.845925Z","iopub.execute_input":"2024-08-14T17:55:10.846620Z","iopub.status.idle":"2024-08-14T17:55:10.855914Z","shell.execute_reply.started":"2024-08-14T17:55:10.846586Z","shell.execute_reply":"2024-08-14T17:55:10.854984Z"},"trusted":true},"execution_count":142,"outputs":[{"execution_count":142,"output_type":"execute_result","data":{"text/plain":"array([-0.11116582,  0.21987572,  0.29978308,  0.29003227,  0.17149012,\n       -0.91148967,  0.31278113,  0.7624278 , -0.22253513, -0.07071584,\n       -0.14928366, -0.5358392 , -0.07174309,  0.35160124,  0.20573623,\n       -0.44041222,  0.10042637, -0.3176769 ,  0.00439161, -0.766483  ,\n        0.39480457,  0.25307393,  0.06425318, -0.14292373,  0.12103537,\n       -0.11990966, -0.11357976, -0.43438816, -0.36182   ,  0.13952059,\n        0.21857938, -0.16307195,  0.22369158, -0.29685947, -0.25333363,\n        0.17421983, -0.10944892, -0.5011487 , -0.44003755, -0.81734693,\n       -0.2644002 , -0.19969364, -0.21387358, -0.24761018,  0.04321107,\n       -0.15683733, -0.6571766 , -0.04763581,  0.15349372,  0.56232256,\n        0.14128423, -0.2854681 , -0.4428264 , -0.28305885, -0.23466843,\n       -0.2568908 ,  0.47744018, -0.16676001, -0.37928852,  0.34662628,\n        0.33083048,  0.06189987, -0.19359416, -0.10445771, -0.58696496,\n        0.19484365, -0.18678547,  0.24151275, -0.60332346,  0.20532529,\n       -0.21875277,  0.40643227,  0.18275535, -0.17660363,  0.45433   ,\n       -0.33303788,  0.08447526, -0.03409669, -0.7459402 ,  0.00187297,\n        0.12394869, -0.05873428,  0.1463609 ,  0.605175  ,  0.11748798,\n       -0.04323197, -0.3319555 ,  0.14964022,  0.35893103,  0.2843434 ,\n        0.44785866, -0.150506  ,  0.10932738,  0.49941322,  0.608283  ,\n        0.45107925,  0.6015148 , -0.7791742 ,  0.42362452,  0.10854946],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n\nX = []\nfor doc in tqdm(df_train['text'].values):\n    X.append(document_vector(doc))\n    \nX = np.array(X)\nprint(X)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:55:53.754808Z","iopub.execute_input":"2024-08-14T17:55:53.755789Z","iopub.status.idle":"2024-08-14T17:55:56.547629Z","shell.execute_reply.started":"2024-08-14T17:55:53.755753Z","shell.execute_reply":"2024-08-14T17:55:56.546522Z"},"trusted":true},"execution_count":143,"outputs":[{"name":"stderr","text":"100%|██████████| 7613/7613 [00:02<00:00, 2745.95it/s]","output_type":"stream"},{"name":"stdout","text":"[[-0.11116582  0.21987572  0.29978308 ... -0.77917421  0.42362452\n   0.10854946]\n [-0.10902946  0.20381387  0.26623884 ... -0.70551354  0.38621905\n   0.093004  ]\n [-0.04368637  0.07898663  0.1079696  ... -0.28505325  0.14934713\n   0.0381024 ]\n ...\n [-0.05441973  0.09742763  0.11931204 ... -0.33721614  0.18052433\n   0.04752825]\n [-0.06995494  0.1400982   0.19099931 ... -0.49652645  0.2665036\n   0.06758373]\n [-0.13828047  0.24109033  0.31219518 ... -0.87578189  0.46282578\n   0.12479699]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-14T17:57:34.463735Z","iopub.execute_input":"2024-08-14T17:57:34.464979Z","iopub.status.idle":"2024-08-14T17:57:34.470964Z","shell.execute_reply.started":"2024-08-14T17:57:34.464941Z","shell.execute_reply":"2024-08-14T17:57:34.469925Z"},"trusted":true},"execution_count":144,"outputs":[{"execution_count":144,"output_type":"execute_result","data":{"text/plain":"(7613, 100)"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n\n# Features and target variable\n# X = df_train.drop('target', axis=1)  \ny = df_train['target']  \n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T18:04:23.436341Z","iopub.execute_input":"2024-08-14T18:04:23.437238Z","iopub.status.idle":"2024-08-14T18:04:23.454214Z","shell.execute_reply.started":"2024-08-14T18:04:23.437205Z","shell.execute_reply":"2024-08-14T18:04:23.453088Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nrf = RandomForestClassifier()\nrf.fit(X_train,y_train)\ny_pred = rf.predict(X_test)\naccuracy_score(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T18:04:25.215550Z","iopub.execute_input":"2024-08-14T18:04:25.215958Z","iopub.status.idle":"2024-08-14T18:04:32.380076Z","shell.execute_reply.started":"2024-08-14T18:04:25.215926Z","shell.execute_reply":"2024-08-14T18:04:32.379065Z"},"trusted":true},"execution_count":146,"outputs":[{"execution_count":146,"output_type":"execute_result","data":{"text/plain":"0.6986211424819435"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncount_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(df_train.text)\nX_train_counts.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:50:08.782313Z","iopub.execute_input":"2024-08-15T06:50:08.783316Z","iopub.status.idle":"2024-08-15T06:50:08.967196Z","shell.execute_reply.started":"2024-08-15T06:50:08.783277Z","shell.execute_reply":"2024-08-15T06:50:08.966049Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"(7613, 12918)"},"metadata":{}}]},{"cell_type":"code","source":"X_train_counts.todense()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:50:22.846623Z","iopub.execute_input":"2024-08-15T06:50:22.847098Z","iopub.status.idle":"2024-08-15T06:50:23.047483Z","shell.execute_reply.started":"2024-08-15T06:50:22.847061Z","shell.execute_reply":"2024-08-15T06:50:23.045944Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"matrix([[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\ntf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\nX_train_tf = tf_transformer.transform(X_train_counts)\nX_train_tf.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:50:45.597614Z","iopub.execute_input":"2024-08-15T06:50:45.598094Z","iopub.status.idle":"2024-08-15T06:50:45.616205Z","shell.execute_reply.started":"2024-08-15T06:50:45.598059Z","shell.execute_reply":"2024-08-15T06:50:45.615042Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(7613, 12918)"},"metadata":{}}]},{"cell_type":"code","source":"target_names = [ 'not a disaster','real disaster', ]","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:52:46.902153Z","iopub.execute_input":"2024-08-15T06:52:46.902629Z","iopub.status.idle":"2024-08-15T06:52:46.908406Z","shell.execute_reply.started":"2024-08-15T06:52:46.902589Z","shell.execute_reply":"2024-08-15T06:52:46.907085Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB().fit(X_train_tfidf,df_train.target)\n\ndocs_new = ['It happened a terrible crash', 'Losing his job was a financial catastrophe for his family']\nX_new_counts = count_vect.transform(docs_new)\nX_new_tfidf = tfidf_transformer.transform(X_new_counts)\npredicted = clf.predict(X_new_tfidf)\nfor doc, category in zip(docs_new, predicted):\n    print('%r => %s' % (doc, target_names[category]))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:52:48.297402Z","iopub.execute_input":"2024-08-15T06:52:48.298153Z","iopub.status.idle":"2024-08-15T06:52:48.319465Z","shell.execute_reply.started":"2024-08-15T06:52:48.298100Z","shell.execute_reply":"2024-08-15T06:52:48.317962Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"'It happened a terrible crash' => real disaster\n'Losing his job was a financial catastrophe for his family' => not a disaster\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\n\n\nX_train, X_valid, y_train, y_valid = train_test_split(df_train.text, df_train.target, test_size=0.20, random_state=42)\n\ntext_clf = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', MultinomialNB()),\n    ])\n\ntext_clf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:53:23.680444Z","iopub.execute_input":"2024-08-15T06:53:23.680845Z","iopub.status.idle":"2024-08-15T06:53:23.862610Z","shell.execute_reply.started":"2024-08-15T06:53:23.680816Z","shell.execute_reply":"2024-08-15T06:53:23.861319Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n                ('clf', MultinomialNB())])","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import f1_score\n\npredicted = text_clf.predict(X_valid)\n\nf1_score(y_valid,predicted)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:53:32.372420Z","iopub.execute_input":"2024-08-15T06:53:32.372855Z","iopub.status.idle":"2024-08-15T06:53:32.419156Z","shell.execute_reply.started":"2024-08-15T06:53:32.372821Z","shell.execute_reply":"2024-08-15T06:53:32.417974Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"0.7362171331636981"},"metadata":{}}]},{"cell_type":"markdown","source":"## SGDClassifier","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\ntext_clf = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n        alpha=1e-3, random_state=42,\n        max_iter=5, tol=None)),\n    ])\ntext_clf.fit(X_train, y_train)\npredicted = text_clf.predict(X_valid)\nf1_score(y_valid,predicted)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:54:25.072160Z","iopub.execute_input":"2024-08-15T06:54:25.072642Z","iopub.status.idle":"2024-08-15T06:54:25.326833Z","shell.execute_reply.started":"2024-08-15T06:54:25.072605Z","shell.execute_reply":"2024-08-15T06:54:25.325106Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"0.641051567239636"},"metadata":{}}]},{"cell_type":"markdown","source":"## RandomForest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\ntext_clf = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', RandomForestClassifier(n_estimators=1000, class_weight = 'balanced')),\n    ])\ntext_clf.fit(X_train, y_train)\npredicted = text_clf.predict(X_valid)\nf1_score(y_valid,predicted)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:54:54.511914Z","iopub.execute_input":"2024-08-15T06:54:54.512374Z","iopub.status.idle":"2024-08-15T06:57:06.426830Z","shell.execute_reply.started":"2024-08-15T06:54:54.512341Z","shell.execute_reply":"2024-08-15T06:57:06.425316Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"0.7325769854132901"},"metadata":{}}]},{"cell_type":"markdown","source":"## LogisticRegression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\ntext_clf = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', LogisticRegression(class_weight = 'balanced',max_iter=5000)),\n    ])\ntext_clf.fit(X_train, y_train)\npredicted = text_clf.predict(X_valid)\nf1_score(y_valid,predicted)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:57:06.430520Z","iopub.execute_input":"2024-08-15T06:57:06.431908Z","iopub.status.idle":"2024-08-15T06:57:07.096397Z","shell.execute_reply.started":"2024-08-15T06:57:06.431839Z","shell.execute_reply":"2024-08-15T06:57:07.094973Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"0.7523364485981309"},"metadata":{}}]},{"cell_type":"code","source":"wrong_df = pd.DataFrame()\nwrong_df['wrong'] = (predicted != y_valid)\nwrong_df['text'] = X_valid\nwrong_df['target'] = y_valid.map({ 0:target_names[0],1:target_names[1],})\n\nwrong_df = wrong_df[wrong_df['wrong'] == True]\nwrong_df","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:57:27.287334Z","iopub.execute_input":"2024-08-15T06:57:27.287777Z","iopub.status.idle":"2024-08-15T06:57:27.311808Z","shell.execute_reply.started":"2024-08-15T06:57:27.287740Z","shell.execute_reply":"2024-08-15T06:57:27.310397Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"      wrong                                               text          target\n2644   True          new weapon cause unimaginable destruction   real disaster\n1765   True  favourite lady came volunteer meeting hopefull...   real disaster\n1817   True  brian emile us fail ems people want insert rem...   real disaster\n4019   True  bringing the tornadoes floods bringing the cli...  not a disaster\n2534   True  escape the heat the trail run desolation loop ...  not a disaster\n...     ...                                                ...             ...\n5148   True  snow wolf party besides would rather shut whol...   real disaster\n5045   True  first tears eyes getting gbbo2015 physically g...   real disaster\n6565   True                        dying debt costly survivors  not a disaster\n4235   True             caution breathing may hazardous health  not a disaster\n1835   True                      smusx16475 skype crashed host  not a disaster\n\n[318 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wrong</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2644</th>\n      <td>True</td>\n      <td>new weapon cause unimaginable destruction</td>\n      <td>real disaster</td>\n    </tr>\n    <tr>\n      <th>1765</th>\n      <td>True</td>\n      <td>favourite lady came volunteer meeting hopefull...</td>\n      <td>real disaster</td>\n    </tr>\n    <tr>\n      <th>1817</th>\n      <td>True</td>\n      <td>brian emile us fail ems people want insert rem...</td>\n      <td>real disaster</td>\n    </tr>\n    <tr>\n      <th>4019</th>\n      <td>True</td>\n      <td>bringing the tornadoes floods bringing the cli...</td>\n      <td>not a disaster</td>\n    </tr>\n    <tr>\n      <th>2534</th>\n      <td>True</td>\n      <td>escape the heat the trail run desolation loop ...</td>\n      <td>not a disaster</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5148</th>\n      <td>True</td>\n      <td>snow wolf party besides would rather shut whol...</td>\n      <td>real disaster</td>\n    </tr>\n    <tr>\n      <th>5045</th>\n      <td>True</td>\n      <td>first tears eyes getting gbbo2015 physically g...</td>\n      <td>real disaster</td>\n    </tr>\n    <tr>\n      <th>6565</th>\n      <td>True</td>\n      <td>dying debt costly survivors</td>\n      <td>not a disaster</td>\n    </tr>\n    <tr>\n      <th>4235</th>\n      <td>True</td>\n      <td>caution breathing may hazardous health</td>\n      <td>not a disaster</td>\n    </tr>\n    <tr>\n      <th>1835</th>\n      <td>True</td>\n      <td>smusx16475 skype crashed host</td>\n      <td>not a disaster</td>\n    </tr>\n  </tbody>\n</table>\n<p>318 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":" ## Parameter tuning","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparameters = {\n    'vect__ngram_range': [(1, 1), (1, 2),(1, 3)],\n    'tfidf__use_idf': (True, False),\n    #'clf__penalty': (None,'l2'),\n    'clf__C' : (0.1, 0.5, 1, 1.5, 2, 2.5, 3)\n     \n    }\n\ngs_clf = GridSearchCV(text_clf, parameters, cv=5, scoring='f1',n_jobs=-1)\ngs_clf = gs_clf.fit(X_train, y_train)\npredicted = gs_clf.predict(X_valid)\nf1_score(y_valid,predicted)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:58:07.995853Z","iopub.execute_input":"2024-08-15T06:58:07.996471Z","iopub.status.idle":"2024-08-15T06:59:07.298771Z","shell.execute_reply.started":"2024-08-15T06:58:07.996425Z","shell.execute_reply":"2024-08-15T06:59:07.297086Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"0.752521334367727"},"metadata":{}}]},{"cell_type":"code","source":"print(gs_clf.best_score_)\nfor param_name in sorted(parameters.keys()):\n    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:59:17.057088Z","iopub.execute_input":"2024-08-15T06:59:17.057536Z","iopub.status.idle":"2024-08-15T06:59:17.065250Z","shell.execute_reply.started":"2024-08-15T06:59:17.057497Z","shell.execute_reply":"2024-08-15T06:59:17.063652Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"0.7596566152267953\nclf__C: 2\ntfidf__use_idf: True\nvect__ngram_range: (1, 2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## test sample","metadata":{}},{"cell_type":"code","source":"submission_df = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv',usecols=[0,])\nsubmission_df['target']=gs_clf.predict(df_test.text)\nsubmission_df.to_csv('submission_partialy_trained.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T06:59:58.722394Z","iopub.execute_input":"2024-08-15T06:59:58.722862Z","iopub.status.idle":"2024-08-15T06:59:58.885932Z","shell.execute_reply.started":"2024-08-15T06:59:58.722823Z","shell.execute_reply":"2024-08-15T06:59:58.884560Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\ntext_clf = Pipeline([\n    ('vect', CountVectorizer(ngram_range = (1, 2))),\n    ('tfidf', TfidfTransformer(use_idf=True)),\n    ('clf', LogisticRegression(class_weight = 'balanced',max_iter=5000, C=3,)),\n    ])\ntext_clf.fit(df_train.text, df_train.target)\nsubmission_df['target']=gs_clf.predict(df_test.text)\n#submission_df.to_csv('submission_full_trained.csv',index=False)\nsubmission_df.to_csv('submission1.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T07:01:17.061727Z","iopub.execute_input":"2024-08-15T07:01:17.062194Z","iopub.status.idle":"2024-08-15T07:01:19.676359Z","shell.execute_reply.started":"2024-08-15T07:01:17.062151Z","shell.execute_reply":"2024-08-15T07:01:19.675081Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# Embedding & Encoding Text\n## TF-IDF Encoding","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# learns the vocabulary of the training data (how important a word is)\nvectorizer = TfidfVectorizer()\nvectorizer.fit(df_train['text'])\n\n# builds feature vectors for each doc - if a word does not appear, it gets a score of 0.0\ntfidf_X = vectorizer.transform(df_train['text'])\n\n# returns list with each elem as feature learned during fit(), ordered by feature index.\nfeature_names = vectorizer.get_feature_names_out()\n\npd.DataFrame(tfidf_X.toarray(), columns=feature_names).iloc[:, :].head(10)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:07:29.716122Z","iopub.execute_input":"2024-08-15T08:07:29.716820Z","iopub.status.idle":"2024-08-15T08:07:30.332211Z","shell.execute_reply.started":"2024-08-15T08:07:29.716785Z","shell.execute_reply":"2024-08-15T08:07:30.331089Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"   001116  005225  010156  010217  010401  012032  012624  015025  030811  \\\n0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n5     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n6     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n7     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n8     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n9     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n\n   05082015  ...  zzz  åèmgnafricaå  ûïbbcwomanshour  ûïleoblakecarter  \\\n0       0.0  ...  0.0           0.0              0.0               0.0   \n1       0.0  ...  0.0           0.0              0.0               0.0   \n2       0.0  ...  0.0           0.0              0.0               0.0   \n3       0.0  ...  0.0           0.0              0.0               0.0   \n4       0.0  ...  0.0           0.0              0.0               0.0   \n5       0.0  ...  0.0           0.0              0.0               0.0   \n6       0.0  ...  0.0           0.0              0.0               0.0   \n7       0.0  ...  0.0           0.0              0.0               0.0   \n8       0.0  ...  0.0           0.0              0.0               0.0   \n9       0.0  ...  0.0           0.0              0.0               0.0   \n\n   ûïlordbrathwaite  ûïmacdaddyleo  ûïsplottdave  ûïthehighfessions  ûò800000  \\\n0               0.0            0.0           0.0                0.0       0.0   \n1               0.0            0.0           0.0                0.0       0.0   \n2               0.0            0.0           0.0                0.0       0.0   \n3               0.0            0.0           0.0                0.0       0.0   \n4               0.0            0.0           0.0                0.0       0.0   \n5               0.0            0.0           0.0                0.0       0.0   \n6               0.0            0.0           0.0                0.0       0.0   \n7               0.0            0.0           0.0                0.0       0.0   \n8               0.0            0.0           0.0                0.0       0.0   \n9               0.0            0.0           0.0                0.0       0.0   \n\n   ûòåêcnbc  \n0       0.0  \n1       0.0  \n2       0.0  \n3       0.0  \n4       0.0  \n5       0.0  \n6       0.0  \n7       0.0  \n8       0.0  \n9       0.0  \n\n[10 rows x 12918 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>001116</th>\n      <th>005225</th>\n      <th>010156</th>\n      <th>010217</th>\n      <th>010401</th>\n      <th>012032</th>\n      <th>012624</th>\n      <th>015025</th>\n      <th>030811</th>\n      <th>05082015</th>\n      <th>...</th>\n      <th>zzz</th>\n      <th>åèmgnafricaå</th>\n      <th>ûïbbcwomanshour</th>\n      <th>ûïleoblakecarter</th>\n      <th>ûïlordbrathwaite</th>\n      <th>ûïmacdaddyleo</th>\n      <th>ûïsplottdave</th>\n      <th>ûïthehighfessions</th>\n      <th>ûò800000</th>\n      <th>ûòåêcnbc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 12918 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## BERT Encoding\n## Now to train on a Sentence Transformer.","metadata":{}},{"cell_type":"code","source":"!pip install sentence_transformers\nfrom sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\nembeddings = model.encode(df_train['text'].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:07:31.991709Z","iopub.execute_input":"2024-08-15T08:07:31.992129Z","iopub.status.idle":"2024-08-15T08:07:59.298977Z","shell.execute_reply.started":"2024-08-15T08:07:31.992100Z","shell.execute_reply":"2024-08-15T08:07:59.297983Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.42.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.23.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence_transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-3.0.1\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efe8688ef25c40b0aeec01d9df89ddc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a65dc03639b4235a46f9f4eaf8554c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"212d00e079d744a68ae1cd6b4ae8755f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d48eb43f416b473fb77e26b3b96e218b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d31658ee10034f22a95ef3f78777d70d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"899977b15798459fa07d800f6e6e7528"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deb31e40bbaa4027954834e4c26119f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7217dcbde96641be851a5fb4c80c5b0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eca4454d354944a48abe5fe1b5a54d51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"720b2dde89234bf5a298cd8660c309f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d6242be7d594072bbb084b4383712ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/238 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d89e48d2941d495ea4c44f58b52f2e2b"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Baseline Models\n## Train / Test Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    tfidf_X, df_train['target'], test_size=0.2, random_state=1\n)\n\n# Repeat the process for the BERT model\nX_train_BERT, X_test_BERT, y_train_BERT, y_test_BERT = train_test_split(\n    embeddings, df_train['target'], test_size=0.2, random_state=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:08:23.276392Z","iopub.execute_input":"2024-08-15T08:08:23.277621Z","iopub.status.idle":"2024-08-15T08:08:23.295921Z","shell.execute_reply.started":"2024-08-15T08:08:23.277587Z","shell.execute_reply":"2024-08-15T08:08:23.294939Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Random Forest Classifier\nFirst, a baseline model for the TF-IDF encoding","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\nrf_clf = RandomForestClassifier()\nrf_clf.fit(X_train, y_train)\n\ny_pred = rf_clf.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred), '\\n')\n\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:08:26.146445Z","iopub.execute_input":"2024-08-15T08:08:26.146853Z","iopub.status.idle":"2024-08-15T08:08:53.593933Z","shell.execute_reply.started":"2024-08-15T08:08:26.146819Z","shell.execute_reply":"2024-08-15T08:08:53.592832Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Accuracy: 0.7846355876559422 \n\n              precision    recall  f1-score   support\n\n           0       0.78      0.88      0.83       882\n           1       0.80      0.66      0.72       641\n\n    accuracy                           0.78      1523\n   macro avg       0.79      0.77      0.77      1523\nweighted avg       0.79      0.78      0.78      1523\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now I'll repeat the same default model for the BERT encoding","metadata":{}},{"cell_type":"code","source":"rf_clf_BERT = RandomForestClassifier()\nrf_clf_BERT.fit(X_train_BERT, y_train_BERT)\n\ny_pred = rf_clf_BERT.predict(X_test_BERT)\nprint(\"Accuracy:\", accuracy_score(y_test_BERT, y_pred), '\\n')\n\nprint(classification_report(y_test_BERT, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:08:53.595630Z","iopub.execute_input":"2024-08-15T08:08:53.595945Z","iopub.status.idle":"2024-08-15T08:09:04.929199Z","shell.execute_reply.started":"2024-08-15T08:08:53.595918Z","shell.execute_reply":"2024-08-15T08:09:04.927962Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Accuracy: 0.7866053841103086 \n\n              precision    recall  f1-score   support\n\n           0       0.77      0.90      0.83       882\n           1       0.82      0.64      0.72       641\n\n    accuracy                           0.79      1523\n   macro avg       0.79      0.77      0.77      1523\nweighted avg       0.79      0.79      0.78      1523\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Logistic Regression¶\nAgain, will compare the two embedding techniques using baseline Logistic Regression model.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg_clf = LogisticRegression(max_iter=1000)\nlogreg_clf.fit(X_train, y_train)\n\ny_pred = logreg_clf.predict(X_test)\n\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred), '\\n')\n\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:09:04.930380Z","iopub.execute_input":"2024-08-15T08:09:04.930682Z","iopub.status.idle":"2024-08-15T08:09:06.154296Z","shell.execute_reply.started":"2024-08-15T08:09:04.930656Z","shell.execute_reply":"2024-08-15T08:09:06.152011Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Accuracy: 0.7977675640183848 \n\n              precision    recall  f1-score   support\n\n           0       0.77      0.92      0.84       882\n           1       0.85      0.63      0.72       641\n\n    accuracy                           0.80      1523\n   macro avg       0.81      0.77      0.78      1523\nweighted avg       0.81      0.80      0.79      1523\n\n","output_type":"stream"}]},{"cell_type":"code","source":"logreg_clf_BERT = LogisticRegression(max_iter=1000)\nlogreg_clf_BERT.fit(X_train_BERT, y_train_BERT)\n\ny_pred = logreg_clf_BERT.predict(X_test_BERT)\n\nprint(\"Accuracy:\", accuracy_score(y_test_BERT, y_pred), '\\n')\n\nprint(classification_report(y_test_BERT, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:09:24.716449Z","iopub.execute_input":"2024-08-15T08:09:24.716849Z","iopub.status.idle":"2024-08-15T08:09:24.846856Z","shell.execute_reply.started":"2024-08-15T08:09:24.716819Z","shell.execute_reply":"2024-08-15T08:09:24.845641Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Accuracy: 0.8056467498358503 \n\n              precision    recall  f1-score   support\n\n           0       0.82      0.85      0.83       882\n           1       0.78      0.75      0.76       641\n\n    accuracy                           0.81      1523\n   macro avg       0.80      0.80      0.80      1523\nweighted avg       0.80      0.81      0.80      1523\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Model Fine Tuning\nLogistic Regression models seem to outperform Random Forest classifiers, and the BERT encoding has an approx +2% edge over TF-IDF encoding. I'll now perform grid search over the BERT encoded data to fine tune my Logistic Regression models.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'C': [0.01, 0.1, 1, 10, 100, 1000],\n    'penalty': ['l2', None],\n    'class_weight': ['balanced', None],\n    'max_iter': [1000, 2000]\n}\n\n# These are the params which got the best results\nparam_grid = {\n    'C': [0.1]\n    , 'class_weight': [None]\n    , 'max_iter': [1000]\n    , 'penalty': ['l2']\n}\n\n# Initialize the classifier\nlog_reg_BERT = LogisticRegression()\n\ngrid_search_BERT = GridSearchCV(\n    estimator=log_reg_BERT\n    , param_grid=param_grid\n    , cv=3\n    , verbose=2\n    , n_jobs=-1\n)\ngrid_search_BERT.fit(X_train_BERT, y_train_BERT)\n\n# Create a new classifier based on the best model \nprint('Highest performing parameters from CV Grid Search: ', grid_search_BERT.best_params_)\nlog_reg_BERT = grid_search_BERT.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:09:25.681462Z","iopub.execute_input":"2024-08-15T08:09:25.682090Z","iopub.status.idle":"2024-08-15T08:09:27.727180Z","shell.execute_reply.started":"2024-08-15T08:09:25.682060Z","shell.execute_reply":"2024-08-15T08:09:27.725564Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid = os.fork()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n/opt/conda/lib/python3.10/site-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid = os.fork()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Highest performing parameters from CV Grid Search:  {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2'}\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = log_reg_BERT.predict(X_test_BERT)\n\nprint(\"Randomised Search LR Accuracy:\", accuracy_score(y_test_BERT, y_pred), '\\n')\nprint(classification_report(y_test_BERT, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:09:32.781246Z","iopub.execute_input":"2024-08-15T08:09:32.782189Z","iopub.status.idle":"2024-08-15T08:09:32.806579Z","shell.execute_reply.started":"2024-08-15T08:09:32.782131Z","shell.execute_reply":"2024-08-15T08:09:32.805493Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Randomised Search LR Accuracy: 0.7951411687458962 \n\n              precision    recall  f1-score   support\n\n           0       0.81      0.85      0.83       882\n           1       0.77      0.72      0.75       641\n\n    accuracy                           0.80      1523\n   macro avg       0.79      0.79      0.79      1523\nweighted avg       0.79      0.80      0.79      1523\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nclf = RandomForestClassifier(bootstrap=False)\n\nparam_grid = {\n    'max_depth': [70, 80, 90, 100, None],\n    'min_samples_leaf': [1, 2, 3],\n    'min_samples_split': [4, 5, 6],\n    'n_estimators': [200, 300, 400, 500],\n    'bootstrap': [True, False]\n    \n}\n\n# Ran previously and here were the highest performing parameters from CV Search:\nparam_grid = {\n    'n_estimators': [400]\n    , 'min_samples_split': [5]\n    , 'min_samples_leaf': [1]\n    , 'max_depth': [90]\n    , 'bootstrap': [False]\n }\n\ngrid_search_BERT = RandomizedSearchCV(\n    estimator = clf\n    , param_distributions = param_grid\n    , n_iter = 100\n    , cv = 3\n    , verbose=1\n    , random_state=42\n    , n_jobs = -1\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:09:35.416350Z","iopub.execute_input":"2024-08-15T08:09:35.417273Z","iopub.status.idle":"2024-08-15T08:09:35.424697Z","shell.execute_reply.started":"2024-08-15T08:09:35.417238Z","shell.execute_reply":"2024-08-15T08:09:35.423719Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\")\n\ngrid_search_BERT.fit(X_train_BERT, y_train_BERT)\n\n# Create a new classifier based on the best model \nprint('Highest performing parameters: ', grid_search_BERT.best_params_)\nrf_clf_BERT = grid_search_BERT.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:09:36.011212Z","iopub.execute_input":"2024-08-15T08:09:36.011722Z","iopub.status.idle":"2024-08-15T08:11:31.797236Z","shell.execute_reply.started":"2024-08-15T08:09:36.011689Z","shell.execute_reply":"2024-08-15T08:11:31.796156Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 1 candidates, totalling 3 fits\nHighest performing parameters:  {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 90, 'bootstrap': False}\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_BERT = rf_clf_BERT.predict(X_test_BERT)\n\nprint(\"Randomised Search RF Accuracy (BERT Encoding):\", accuracy_score(y_test_BERT, y_pred_BERT), '\\n')\nprint(classification_report(y_test_BERT, y_pred_BERT))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:11:37.206622Z","iopub.execute_input":"2024-08-15T08:11:37.207560Z","iopub.status.idle":"2024-08-15T08:11:37.398791Z","shell.execute_reply.started":"2024-08-15T08:11:37.207520Z","shell.execute_reply":"2024-08-15T08:11:37.397673Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Randomised Search RF Accuracy (BERT Encoding): 0.7977675640183848 \n\n              precision    recall  f1-score   support\n\n           0       0.79      0.90      0.84       882\n           1       0.82      0.66      0.73       641\n\n    accuracy                           0.80      1523\n   macro avg       0.80      0.78      0.79      1523\nweighted avg       0.80      0.80      0.79      1523\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"I'll now try building a VotingClassifier with the log_reg and rf_clf model.","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\nfrom sklearn.ensemble import VotingClassifier\n\n# define the individual models\nestimators = [\n    ('Random Forest Classifier', rf_clf_BERT), \n    ('Logistic Regression Classifier', log_reg_BERT)\n]\n\n# create the ensemble model\nhard_voting_clf = VotingClassifier(estimators=estimators, voting='hard')\nsoft_voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n\n# list of classifiers for easy iteration\nclassifiers = [hard_voting_clf, soft_voting_clf]\n\n# fit each classifier and print their performance\nfor clf in classifiers:\n    clf_name = clf.__class__.__name__\n    if clf == soft_voting_clf:\n        clf_name = \"Soft \" + clf_name\n    else:\n        clf_name = \"Hard \" + clf_name\n\n    # train the voting classifier\n    clf.fit(X_train_BERT, y_train_BERT)\n    \n    # make predictions\n    y_pred = clf.predict(X_test_BERT)\n\n    # calculate and print accuracy score\n    accuracy = accuracy_score(y_test_BERT, y_pred)\n    print(f\"{clf_name} Accuracy: {accuracy}\")\n\n    # print classification report\n    report = classification_report(y_test_BERT, y_pred)\n    print(f\"{clf_name} Classification Report: \\n{report}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:11:49.691024Z","iopub.execute_input":"2024-08-15T08:11:49.691428Z","iopub.status.idle":"2024-08-15T08:14:01.136987Z","shell.execute_reply.started":"2024-08-15T08:11:49.691397Z","shell.execute_reply":"2024-08-15T08:14:01.132893Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Hard VotingClassifier Accuracy: 0.8049901510177282\nHard VotingClassifier Classification Report: \n              precision    recall  f1-score   support\n\n           0       0.78      0.92      0.85       882\n           1       0.86      0.64      0.74       641\n\n    accuracy                           0.80      1523\n   macro avg       0.82      0.78      0.79      1523\nweighted avg       0.81      0.80      0.80      1523\n\nSoft VotingClassifier Accuracy: 0.8023637557452397\nSoft VotingClassifier Classification Report: \n              precision    recall  f1-score   support\n\n           0       0.80      0.87      0.84       882\n           1       0.80      0.70      0.75       641\n\n    accuracy                           0.80      1523\n   macro avg       0.80      0.79      0.79      1523\nweighted avg       0.80      0.80      0.80      1523\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Importing Test Data and Sentence Transformer\ndf_test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nmodel = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n\n# # TF-IDF Vectorisation\nnew_test_data_vectorized = model.encode(df_test['text'].tolist())\noutput_df = pd.DataFrame({'id': df_test['id'], 'target': soft_voting_clf.predict(new_test_data_vectorized)})\noutput_df.to_csv('nlp_submission2.csv', index=False)\n# output_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:14:01.140385Z","iopub.execute_input":"2024-08-15T08:14:01.140990Z","iopub.status.idle":"2024-08-15T08:14:04.407574Z","shell.execute_reply.started":"2024-08-15T08:14:01.140936Z","shell.execute_reply":"2024-08-15T08:14:04.405890Z"},"trusted":true},"execution_count":56,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23967da9a44943a1941b1308408546eb"}},"metadata":{}}]},{"cell_type":"markdown","source":"Tested on the Competition Test Data, this got me 80.005%, putting me in the 413rd percentile. Not bad for a second attempt! Having switched out to a new Sentence Transformer, I got X.X%.\n\nMaybe adding a Deep Learning based method into my ensemble classifier will improve it?","metadata":{}},{"cell_type":"markdown","source":"# Round 2: Tensorflow Modelling¶\nAfter a lot of tweaking, I have a model which performs pretty well!","metadata":{}},{"cell_type":"code","source":"pip install tensorflow-addons==0.19.0","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:14:12.342196Z","iopub.execute_input":"2024-08-15T08:14:12.342604Z","iopub.status.idle":"2024-08-15T08:14:25.521002Z","shell.execute_reply.started":"2024-08-15T08:14:12.342576Z","shell.execute_reply":"2024-08-15T08:14:25.519563Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: tensorflow-addons==0.19.0 in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons==0.19.0) (21.3)\nRequirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons==0.19.0) (2.13.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow-addons==0.19.0) (3.1.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install --upgrade tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:14:25.523402Z","iopub.execute_input":"2024-08-15T08:14:25.523738Z","iopub.status.idle":"2024-08-15T08:14:39.309049Z","shell.execute_reply.started":"2024-08-15T08:14:25.523708Z","shell.execute_reply":"2024-08-15T08:14:39.307879Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.17.0)\n[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l2; total time=   0.0s\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.18,>=2.17 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.17.1)\nRequirement already satisfied: keras>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, MaxPooling1D, Conv1D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.metrics import AUC, Precision, Recall\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import backend as K\n\n# Custom F1 Score function\ndef f1_score(y_true, y_pred):\n    y_true = K.cast(y_true, 'float32')  # Cast y_true to float32\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (possible_positives + K.epsilon())\n    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n    return f1_val\n\n# Assuming X_train_BERT and y_train_BERT are predefined\nnum_features = X_train_BERT.shape[1]\n\ndef build_nn():\n    model = Sequential()\n    model.add(tf.keras.layers.Reshape((num_features, 1), input_shape=(num_features,)))\n    model.add(Conv1D(activation='relu', filters=64, kernel_size=4, strides=1, padding='same'))\n    model.add(MaxPooling1D(2))\n    model.add(tf.keras.layers.Flatten())\n    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n    model.add(Dense(1, activation='sigmoid'))\n\n    optimizer = Adam(learning_rate=0.001)  # Use a fixed learning rate\n\n    model.compile(\n        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n        optimizer=optimizer,\n        metrics=['accuracy', Precision(), Recall(), f1_score]  # Include custom F1 score\n    )\n    return model\n\n# Define the EarlyStopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n\n# Define the ModelCheckpoint callback with .keras extension\nmodel_checkpoint = ModelCheckpoint('model.keras', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n\n# Define the ReduceLROnPlateau callback\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=0.00001)\n\n# Fit the model\nkeras_nn = build_nn()\nhistory = keras_nn.fit(\n    X_train_BERT, y_train_BERT, epochs=50, batch_size=8, validation_split=0.2, callbacks=[early_stopping, model_checkpoint, reduce_lr]\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:26:31.172505Z","iopub.execute_input":"2024-08-15T08:26:31.173717Z","iopub.status.idle":"2024-08-15T08:27:16.233243Z","shell.execute_reply.started":"2024-08-15T08:26:31.173675Z","shell.execute_reply":"2024-08-15T08:27:16.232463Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m 53/609\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5795 - f1_score: 0.0342 - loss: 1.3033 - precision_2: 0.4393 - recall_2: 0.0252   ","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1723710399.970295     188 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m599/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6250 - f1_score: 0.2186 - loss: 0.9823 - precision_2: 0.6080 - recall_2: 0.2216","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1723710402.721465     186 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_loss improved from inf to 0.64209, saving model to model.keras\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.6261 - f1_score: 0.2228 - loss: 0.9795 - precision_2: 0.6097 - recall_2: 0.2260 - val_accuracy: 0.7849 - val_f1_score: 0.7098 - val_loss: 0.6421 - val_precision_2: 0.7894 - val_recall_2: 0.7083 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m599/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7779 - f1_score: 0.6932 - loss: 0.6317 - precision_2: 0.7731 - recall_2: 0.6854\nEpoch 2: val_loss did not improve from 0.64209\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7779 - f1_score: 0.6930 - loss: 0.6315 - precision_2: 0.7732 - recall_2: 0.6854 - val_accuracy: 0.6724 - val_f1_score: 0.3849 - val_loss: 0.6983 - val_precision_2: 0.9345 - val_recall_2: 0.2881 - learning_rate: 0.0010\nEpoch 3/50\n\u001b[1m593/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7833 - f1_score: 0.6955 - loss: 0.5953 - precision_2: 0.8078 - recall_2: 0.6724\nEpoch 3: val_loss improved from 0.64209 to 0.56526, saving model to model.keras\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7835 - f1_score: 0.6953 - loss: 0.5949 - precision_2: 0.8076 - recall_2: 0.6726 - val_accuracy: 0.7849 - val_f1_score: 0.6789 - val_loss: 0.5653 - val_precision_2: 0.8494 - val_recall_2: 0.6312 - learning_rate: 0.0010\nEpoch 4/50\n\u001b[1m599/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8099 - f1_score: 0.7181 - loss: 0.5541 - precision_2: 0.8094 - recall_2: 0.7173\nEpoch 4: val_loss improved from 0.56526 to 0.55589, saving model to model.keras\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8097 - f1_score: 0.7180 - loss: 0.5543 - precision_2: 0.8094 - recall_2: 0.7171 - val_accuracy: 0.7915 - val_f1_score: 0.7146 - val_loss: 0.5559 - val_precision_2: 0.7975 - val_recall_2: 0.7156 - learning_rate: 0.0010\nEpoch 5/50\n\u001b[1m599/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7976 - f1_score: 0.6967 - loss: 0.5534 - precision_2: 0.8203 - recall_2: 0.6758\nEpoch 5: val_loss did not improve from 0.55589\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7977 - f1_score: 0.6971 - loss: 0.5533 - precision_2: 0.8203 - recall_2: 0.6763 - val_accuracy: 0.7824 - val_f1_score: 0.6846 - val_loss: 0.5629 - val_precision_2: 0.8333 - val_recall_2: 0.6422 - learning_rate: 0.0010\nEpoch 6/50\n\u001b[1m604/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8109 - f1_score: 0.7160 - loss: 0.5371 - precision_2: 0.8173 - recall_2: 0.7021\nEpoch 6: val_loss did not improve from 0.55589\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8109 - f1_score: 0.7159 - loss: 0.5372 - precision_2: 0.8174 - recall_2: 0.7020 - val_accuracy: 0.7767 - val_f1_score: 0.6740 - val_loss: 0.5596 - val_precision_2: 0.8258 - val_recall_2: 0.6349 - learning_rate: 0.0010\nEpoch 7/50\n\u001b[1m598/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8215 - f1_score: 0.7226 - loss: 0.5209 - precision_2: 0.8380 - recall_2: 0.7216\nEpoch 7: val_loss did not improve from 0.55589\n\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8212 - f1_score: 0.7224 - loss: 0.5214 - precision_2: 0.8377 - recall_2: 0.7214 - val_accuracy: 0.7767 - val_f1_score: 0.6644 - val_loss: 0.5633 - val_precision_2: 0.8527 - val_recall_2: 0.6055 - learning_rate: 0.0010\nEpoch 8/50\n\u001b[1m601/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8385 - f1_score: 0.7499 - loss: 0.5047 - precision_2: 0.8712 - recall_2: 0.7216\nEpoch 8: val_loss improved from 0.55589 to 0.55243, saving model to model.keras\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8385 - f1_score: 0.7500 - loss: 0.5047 - precision_2: 0.8711 - recall_2: 0.7218 - val_accuracy: 0.7931 - val_f1_score: 0.7025 - val_loss: 0.5524 - val_precision_2: 0.8248 - val_recall_2: 0.6826 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m598/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8514 - f1_score: 0.7546 - loss: 0.4781 - precision_2: 0.8807 - recall_2: 0.7445\nEpoch 9: val_loss improved from 0.55243 to 0.55197, saving model to model.keras\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8513 - f1_score: 0.7548 - loss: 0.4782 - precision_2: 0.8807 - recall_2: 0.7444 - val_accuracy: 0.7923 - val_f1_score: 0.7014 - val_loss: 0.5520 - val_precision_2: 0.8244 - val_recall_2: 0.6807 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m598/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8465 - f1_score: 0.7599 - loss: 0.4791 - precision_2: 0.8628 - recall_2: 0.7524\nEpoch 10: val_loss improved from 0.55197 to 0.55026, saving model to model.keras\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8465 - f1_score: 0.7602 - loss: 0.4791 - precision_2: 0.8629 - recall_2: 0.7525 - val_accuracy: 0.7947 - val_f1_score: 0.7067 - val_loss: 0.5503 - val_precision_2: 0.8242 - val_recall_2: 0.6881 - learning_rate: 1.0000e-04\nEpoch 11/50\n\u001b[1m604/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8557 - f1_score: 0.7717 - loss: 0.4499 - precision_2: 0.8817 - recall_2: 0.7548\nEpoch 11: val_loss did not improve from 0.55026\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8557 - f1_score: 0.7717 - loss: 0.4500 - precision_2: 0.8817 - recall_2: 0.7548 - val_accuracy: 0.7923 - val_f1_score: 0.7063 - val_loss: 0.5540 - val_precision_2: 0.8174 - val_recall_2: 0.6899 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m603/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8556 - f1_score: 0.7864 - loss: 0.4581 - precision_2: 0.8823 - recall_2: 0.7650\nEpoch 12: val_loss improved from 0.55026 to 0.54776, saving model to model.keras\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8556 - f1_score: 0.7863 - loss: 0.4581 - precision_2: 0.8823 - recall_2: 0.7649 - val_accuracy: 0.7964 - val_f1_score: 0.7068 - val_loss: 0.5478 - val_precision_2: 0.8322 - val_recall_2: 0.6826 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m597/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8585 - f1_score: 0.7813 - loss: 0.4568 - precision_2: 0.8877 - recall_2: 0.7625\nEpoch 13: val_loss did not improve from 0.54776\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8585 - f1_score: 0.7813 - loss: 0.4568 - precision_2: 0.8876 - recall_2: 0.7626 - val_accuracy: 0.7939 - val_f1_score: 0.7072 - val_loss: 0.5494 - val_precision_2: 0.8281 - val_recall_2: 0.6807 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m604/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8688 - f1_score: 0.7990 - loss: 0.4308 - precision_2: 0.8930 - recall_2: 0.7850\nEpoch 14: val_loss did not improve from 0.54776\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8687 - f1_score: 0.7990 - loss: 0.4309 - precision_2: 0.8930 - recall_2: 0.7849 - val_accuracy: 0.7939 - val_f1_score: 0.7089 - val_loss: 0.5495 - val_precision_2: 0.8168 - val_recall_2: 0.6954 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m603/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8723 - f1_score: 0.7913 - loss: 0.4189 - precision_2: 0.8896 - recall_2: 0.7895\nEpoch 15: val_loss did not improve from 0.54776\n\nEpoch 15: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8721 - f1_score: 0.7912 - loss: 0.4191 - precision_2: 0.8896 - recall_2: 0.7894 - val_accuracy: 0.7956 - val_f1_score: 0.7093 - val_loss: 0.5481 - val_precision_2: 0.8289 - val_recall_2: 0.6844 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m601/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8608 - f1_score: 0.7826 - loss: 0.4372 - precision_2: 0.8918 - recall_2: 0.7686\nEpoch 16: val_loss did not improve from 0.54776\n\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8610 - f1_score: 0.7828 - loss: 0.4371 - precision_2: 0.8920 - recall_2: 0.7688 - val_accuracy: 0.7939 - val_f1_score: 0.7075 - val_loss: 0.5498 - val_precision_2: 0.8238 - val_recall_2: 0.6862 - learning_rate: 1.0000e-05\nEpoch 16: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model\nresults = keras_nn.evaluate(X_test_BERT, y_test_BERT)\n\n# Unpack the results according to the number of metrics\nloss = results[0]\naccuracy = results[1]\nprecision = results[2]\nrecall = results[3]\nf1 = results[4]\n\n# Print the results\nprint(\"Test Loss: \", loss)\nprint(\"Test Accuracy: \", accuracy)\nprint(\"Test Precision: \", precision)\nprint(\"Test Recall: \", recall)\nprint(\"Test F1: \", f1)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:31:13.183241Z","iopub.execute_input":"2024-08-15T08:31:13.183662Z","iopub.status.idle":"2024-08-15T08:31:13.352974Z","shell.execute_reply.started":"2024-08-15T08:31:13.183631Z","shell.execute_reply":"2024-08-15T08:31:13.351988Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8031 - f1_score: 0.7419 - loss: 0.5416 - precision_2: 0.8055 - recall_2: 0.6989\nTest Loss:  0.5406988859176636\nTest Accuracy:  0.8023637533187866\nTest Precision:  0.8068591952323914\nTest Recall:  0.69734787940979\nTest F1:  0.7393319010734558\n","output_type":"stream"}]},{"cell_type":"markdown","source":"I've managed to get roughly the same accuracy on this sequential neural net as I was the other models, now going to try adding it to the Ensemble Model.\n\nIn order to do this, I'll need a wrapper so the sklearn and keras APIs can play nicely together.","metadata":{}},{"cell_type":"code","source":"# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n\n\n# class CustomKerasClassifier(tf.keras.wrappers.scikit_learn.KerasClassifier):\n#     def predict(self, x, **kwargs):\n#         \"\"\"Returns the class prediction of the samples\"\"\"\n#         x = x.toarray() if hasattr(x, 'toarray') else np.array(x)\n#         return super().predict(x, **kwargs)\n    \n#     def predict_proba(self, x, **kwargs):\n#         \"\"\"Returns class probabilities of the samples\"\"\"\n#         x = x.toarray() if hasattr(x, 'toarray') else np.array(x)\n#         proba = super().predict_proba(x, **kwargs)\n        \n#         # Check if it's binary classification\n#         if proba.shape[1] == 1:\n#             # Assuming the single output is the probability of the positive class\n#             return np.hstack([1 - proba, proba])  # shape should be (n_samples, 2)\n\n#         return proba\n\n# keras_clf = CustomKerasClassifier(\n#     build_nn,\n#     epochs=10,\n#     batch_size=8,\n#     validation_split=0.2,\n#     callbacks=[early_stopping, model_checkpoint, reduce_lr]\n# )\n# keras_clf._estimator_type = \"classifier\"","metadata":{"execution":{"iopub.status.busy":"2024-08-15T09:03:43.610934Z","iopub.execute_input":"2024-08-15T09:03:43.611733Z","iopub.status.idle":"2024-08-15T09:03:43.696899Z","shell.execute_reply.started":"2024-08-15T09:03:43.611695Z","shell.execute_reply":"2024-08-15T09:03:43.695425Z"},"trusted":true},"execution_count":90,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[90], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier, KerasRegressor\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomKerasClassifier\u001b[39;00m(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mwrappers\u001b[38;5;241m.\u001b[39mscikit_learn\u001b[38;5;241m.\u001b[39mKerasClassifier):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"],"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow.keras.wrappers'","output_type":"error"}]},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\nfrom sklearn.ensemble import VotingClassifier\nfrom scipy.sparse import csr_matrix\n\n# define the individual models\nestimators = [\n#     ('Keras Neural Network Classifier', keras_clf),\n    ('Random Forest Classifier', rf_clf_BERT), \n    ('Logistic Regression Classifier', log_reg_BERT)\n]\n\n# create the ensemble model\nsoft_voting_clf = VotingClassifier(\n    estimators=estimators, voting='soft', flatten_transform=True\n)\n\nsoft_voting_clf.fit(X_train_BERT, y_train_BERT)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T09:07:01.627021Z","iopub.execute_input":"2024-08-15T09:07:01.627436Z","iopub.status.idle":"2024-08-15T09:08:07.285817Z","shell.execute_reply.started":"2024-08-15T09:07:01.627404Z","shell.execute_reply":"2024-08-15T09:08:07.284453Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"VotingClassifier(estimators=[('Random Forest Classifier',\n                              RandomForestClassifier(bootstrap=False,\n                                                     max_depth=90,\n                                                     min_samples_split=5,\n                                                     n_estimators=400)),\n                             ('Logistic Regression Classifier',\n                              LogisticRegression(C=0.1, max_iter=1000))],\n                 voting='soft')","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;Random Forest Classifier&#x27;,\n                              RandomForestClassifier(bootstrap=False,\n                                                     max_depth=90,\n                                                     min_samples_split=5,\n                                                     n_estimators=400)),\n                             (&#x27;Logistic Regression Classifier&#x27;,\n                              LogisticRegression(C=0.1, max_iter=1000))],\n                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;Random Forest Classifier&#x27;,\n                              RandomForestClassifier(bootstrap=False,\n                                                     max_depth=90,\n                                                     min_samples_split=5,\n                                                     n_estimators=400)),\n                             (&#x27;Logistic Regression Classifier&#x27;,\n                              LogisticRegression(C=0.1, max_iter=1000))],\n                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Random Forest Classifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, max_depth=90, min_samples_split=5,\n                       n_estimators=400)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Logistic Regression Classifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = soft_voting_clf.predict(X_test_BERT)\n\n# # calculate and print accuracy score\naccuracy = accuracy_score(y_test_BERT, y_pred)\nprint(f\"Soft Voting Classifier Accuracy: {accuracy}\")\n\n# # print classification report\nreport = classification_report(y_test_BERT, y_pred)\nprint(f\"Classification Report: \\n{report}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T09:09:17.320238Z","iopub.execute_input":"2024-08-15T09:09:17.321144Z","iopub.status.idle":"2024-08-15T09:09:17.514168Z","shell.execute_reply.started":"2024-08-15T09:09:17.321102Z","shell.execute_reply":"2024-08-15T09:09:17.512946Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"Soft Voting Classifier Accuracy: 0.8023637557452397\nClassification Report: \n              precision    recall  f1-score   support\n\n           0       0.80      0.88      0.84       882\n           1       0.81      0.70      0.75       641\n\n    accuracy                           0.80      1523\n   macro avg       0.80      0.79      0.79      1523\nweighted avg       0.80      0.80      0.80      1523\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Importing Test Data and Sentence Transformer\ndf_test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nmodel = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n\nnew_test_data_vectorized = model.encode(df_test['text'].tolist())\noutput_df = pd.DataFrame({'id': df_test['id'], 'target': soft_voting_clf.predict(new_test_data_vectorized)})\noutput_df.to_csv('nlp_submission3.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T09:09:58.910869Z","iopub.execute_input":"2024-08-15T09:09:58.911827Z","iopub.status.idle":"2024-08-15T09:10:02.072504Z","shell.execute_reply.started":"2024-08-15T09:09:58.911793Z","shell.execute_reply":"2024-08-15T09:10:02.070775Z"},"trusted":true},"execution_count":97,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f0c7d9f963043a3ba2f0bde3c30f40e"}},"metadata":{}}]}]}